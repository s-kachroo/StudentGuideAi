{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bdbbfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(99106) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(99114) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip -q\n",
    "%pip install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926719a487baa87b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T19:11:49.805145Z",
     "start_time": "2025-04-07T19:11:49.798948Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb.utils import embedding_functions\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from textwrap import dedent\n",
    "from torchmetrics.text.bert import BERTScore\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"tqdm\")\n",
    "\n",
    "# Set up OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set up logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3307554d703734c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T19:11:49.819412Z",
     "start_time": "2025-04-07T19:11:49.815104Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pdf_documents(data_dir):\n",
    "    \"\"\"\n",
    "    Loads all PDF files from the specified directory.\n",
    "    Returns a list of document dictionaries.\n",
    "    \"\"\"\n",
    "    documents_list = []\n",
    "    data_path = Path(data_dir)\n",
    "    if not data_path.exists():\n",
    "        raise FileNotFoundError(f\"Data directory not found at {data_path.absolute()}\")\n",
    "    pdf_files = list(data_path.glob(\"*.pdf\"))\n",
    "    if not pdf_files:\n",
    "        raise FileNotFoundError(f\"No PDF files found in {data_path.absolute()}\")\n",
    "    for pdf_file in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "        try:\n",
    "            text = \"\"\n",
    "            with open(pdf_file, \"rb\") as f:\n",
    "                reader = PyPDF2.PdfReader(f)\n",
    "                for page in reader.pages:\n",
    "                    # Use a fallback in case extract_text() returns None\n",
    "                    page_text = page.extract_text() or \"\"\n",
    "                    text += page_text + \"\\n\"\n",
    "            documents_list.append({\n",
    "                \"filepath\": str(pdf_file.absolute()),\n",
    "                \"filename\": pdf_file.name,\n",
    "                \"title\": pdf_file.stem,\n",
    "                \"text\": text,\n",
    "                \"source\": \"CMU Official Documents\"\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {pdf_file.name}: {str(e)}\")\n",
    "            continue\n",
    "    return documents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e83b078f005502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T19:11:49.828668Z",
     "start_time": "2025-04-07T19:11:49.825813Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_document_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by removing extra spaces and some common unwanted patterns.\n",
    "    \"\"\"\n",
    "    text = \" \".join(text.split())\n",
    "    patterns = [r\"page \\d+ of \\d+\", r\"confidential\", r\"Â©\\d+\"]\n",
    "    for pattern in patterns:\n",
    "        text = re.sub(pattern, \"\", text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def chunk_documents(documents_data, chunk_size, chunk_overlap):\n",
    "    \"\"\"\n",
    "    Splits each document's text into chunks (based on words).\n",
    "    Optionally cleans the text before splitting.\n",
    "    Returns a list of chunk dictionaries.\n",
    "    \"\"\"\n",
    "    chunks_list = []\n",
    "    for doc in tqdm(documents_data, desc=\"Chunking documents\"):\n",
    "        text = doc[\"text\"]\n",
    "        text = clean_document_text(text=text)\n",
    "        words = text.split()\n",
    "        # Slide a window over the word list\n",
    "        for i in range(0, len(words), chunk_size - chunk_overlap):\n",
    "            chunk_words = words[i: i + chunk_size]\n",
    "            chunk_text = \" \".join(chunk_words)\n",
    "            chunks_list.append({\n",
    "                \"text\": chunk_text,\n",
    "                \"document_title\": doc[\"title\"],\n",
    "                \"document_source\": doc[\"source\"],\n",
    "                \"chunk_id\": f\"{doc['title']}_{len(chunk_text)}_{hash(chunk_text)}\",\n",
    "                \"metadata\": {\n",
    "                    \"source\": doc[\"source\"],\n",
    "                    \"title\": doc[\"title\"],\n",
    "                    \"filepath\": doc[\"filepath\"]\n",
    "                }\n",
    "            })\n",
    "    return chunks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8365def3b67c86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T19:11:49.837484Z",
     "start_time": "2025-04-07T19:11:49.834602Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_vector_collection(build=False, collection_name=\"cmu_student_guide\", db_path=\"./chroma_db\", data_dir=\"./data\", chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Returns a persistent ChromaDB collection.\n",
    "    If build is set to True, PDFs are processed, chunked, and added to the collection;\n",
    "    otherwise, the saved vector database (in ./chroma_db) is loaded.\n",
    "    \"\"\"\n",
    "    client = chromadb.PersistentClient(\n",
    "        path=db_path,\n",
    "        settings=Settings(anonymized_telemetry=False)\n",
    "    )\n",
    "    rag_collection = client.get_or_create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(\"all-MiniLM-L6-v2\")\n",
    "    )\n",
    "    if build:\n",
    "        # Process PDFs and build the collection.\n",
    "        documents = load_pdf_documents(data_dir=data_dir)\n",
    "        chunks = chunk_documents(documents_data=documents, chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        for i in tqdm(range(0, len(chunks), 100), desc=\"Indexing documents\"):\n",
    "            batch = chunks[i: i + 100]\n",
    "            rag_collection.add(\n",
    "                documents=[chunk[\"text\"] for chunk in batch],\n",
    "                metadatas=[chunk[\"metadata\"] for chunk in batch],\n",
    "                ids=[chunk[\"chunk_id\"] for chunk in batch]\n",
    "            )\n",
    "    return rag_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dace1ee29ecb9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T19:11:49.863543Z",
     "start_time": "2025-04-07T19:11:49.861397Z"
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(rag_collection, query, top_k):\n",
    "    \"\"\"\n",
    "    Queries the vector DB for the most similar document chunks to the query.\n",
    "    Returns the raw query results.\n",
    "    \"\"\"\n",
    "    results = rag_collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=top_k,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "    results[\"scores\"] = [1 - distance for distance in results[\"distances\"][0]]\n",
    "    return results\n",
    "\n",
    "def generate_answer(query, retrieved_chunks, model_name=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Generates an answer by constructing a prompt that includes the retrieved context\n",
    "    and then calling the OpenAI ChatCompletion API.\n",
    "    \"\"\"\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Source: {meta['title']}\\n{doc}\"\n",
    "        for doc, meta in zip(retrieved_chunks[\"documents\"][0], retrieved_chunks[\"metadatas\"][0])\n",
    "    ])\n",
    "\n",
    "    prompt = dedent(f\"\"\"\n",
    "        You are a helpful CMU assistant. Answer based ONLY on this context:\n",
    "        {context}\n",
    "        Question: {query}\n",
    "        Please give concise answer with less than 15 words, meaningful, and cite sources, if possible.\n",
    "        \"\"\")\n",
    "\n",
    "    client = OpenAI(api_key=openai.api_key)\n",
    "    llm_response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a factual CMU student assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    return llm_response.choices[0].message.content\n",
    "\n",
    "def query_cmu_knowledge(rag_collection, user_question, top_k):\n",
    "    \"\"\"\n",
    "    Retrieves document context using the vector DB and generates a final answer.\n",
    "    Returns a dictionary with the question, answer, and source metadata.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        retrieved_chunks = retrieve_relevant_chunks(rag_collection=rag_collection, query=user_question, top_k=top_k)\n",
    "        answer = generate_answer(query=user_question, retrieved_chunks=retrieved_chunks)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "        return {\n",
    "            \"question\": user_question,\n",
    "            \"answer\": answer,\n",
    "            \"sources\": retrieved_chunks['metadatas'][0]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Query failed: {str(e)}\")\n",
    "        return {\n",
    "            \"question\": user_question,\n",
    "            \"answer\": \"Sorry, I couldn't process your question. Please contact The HUB.\",\n",
    "            \"sources\": []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d3b902b8b75e970",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T19:11:49.871713Z",
     "start_time": "2025-04-07T19:11:49.868805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the BERTScore metric for evaluation\n",
    "bertscore_scorer = BERTScore(\n",
    "    model_name_or_path=\"bert-base-uncased\",\n",
    "    num_layers=8,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "# Function to evaluate the generated answer using BERTScore\n",
    "def evaluate_response(generated_answer, reference_answer):\n",
    "    scores = bertscore_scorer(\n",
    "        [generated_answer],\n",
    "        [reference_answer]\n",
    "    )\n",
    "    p = scores[\"precision\"].item()\n",
    "    r = scores[\"recall\"].item()\n",
    "    f = scores[\"f1\"].item()\n",
    "    return p, r, f\n",
    "\n",
    "# Function to run the evaluation on a set of test cases\n",
    "def run_evaluation(collection, test_user_queries, top_k):\n",
    "    results = []\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "    for case in test_user_queries:\n",
    "        print(f\"Evaluating question: {case['question']}\")\n",
    "        response = query_cmu_knowledge(rag_collection=collection, user_question=case['question'], top_k=top_k)\n",
    "        p, r, f = evaluate_response(generated_answer=response['answer'], reference_answer=case['answer'])\n",
    "        precisions.append(p); recalls.append(r); f1s.append(f)\n",
    "        results.append({\n",
    "            \"question\": case['question'],\n",
    "            \"generated_answer\": response['answer'],\n",
    "            \"reference_answer\": case['answer']        \n",
    "        })\n",
    "    print(f\"Precision: {sum(precisions)/len(precisions):.4f}, Recall: {sum(recalls)/len(recalls):.4f}, F1: {sum(f1s)/len(f1s):.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fdf9c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Building the vector database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(99142) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Processing PDFs: 100%|ââââââââââ| 10/10 [00:00<00:00, 54.22it/s]\n",
      "Chunking documents: 100%|ââââââââââ| 10/10 [00:00<00:00, 5117.50it/s]\n",
      "Indexing documents: 100%|ââââââââââ| 1/1 [00:01<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Built the vector database with 41 chunks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the vector database manually.\n",
    "print(f\"[INFO] Building the vector database...\")\n",
    "collection = create_vector_collection(build=True, collection_name=\"cmu_student_guide\", db_path=\"./chroma_db\", data_dir=\"../data\", chunk_size=500, chunk_overlap=300)\n",
    "print(f\"[INFO] Built the vector database with {len(collection.get()['ids'])} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce4b685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the deadline to add a course?, Answer: The deadline to add a course is not specified in the provided context.\n",
      "- cds-2024-h-student-financial-aid-21feb2025\n",
      "- cds-2024-d-transfer-admission-21feb2025\n",
      "- cds-2024-c-first-time-first-year-freshman-admission-21feb2025\n"
     ]
    }
   ],
   "source": [
    "# Run a sample queries to test the system.\n",
    "question1 = \"What is the deadline to add a course?\"\n",
    "response1 = query_cmu_knowledge(rag_collection=collection, user_question=question1, top_k=3)\n",
    "print(f\"Question: {question1}, Answer: {response1['answer']}\")\n",
    "for source in response1['sources']:\n",
    "    print(f\"- {source['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4ab29bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating question: How do I access library resources?\n",
      "Evaluating question: Who is Cathleen Kisak?\n",
      "Precision: 0.5504, Recall: 0.6286, F1: 0.5869\n",
      "[{'question': 'How do I access library resources?', 'generated_answer': 'Access library resources through the CMU library website or visit in person.', 'reference_answer': 'Use your Andrew ID at the library website.'}, {'question': 'Who is Cathleen Kisak?', 'generated_answer': 'Cathleen Kisak is a Research Designer and Analyst at Institutional Research and Analysis. (Source: cds-2024-a-general-information)', 'reference_answer': 'Cathleen Kisak is a faculty member at Carnegie Mellon University, known for her role in the School of Computer Science.'}]\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation on a set of test cases.\n",
    "test_user_queries = [\n",
    "    {\n",
    "        \"question\": \"How do I access library resources?\",\n",
    "        \"answer\": \"Use your Andrew ID at the library website.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who is Cathleen Kisak?\",\n",
    "        \"answer\": \"Cathleen Kisak is a faculty member at Carnegie Mellon University, known for her role in the School of Computer Science.\"\n",
    "    }\n",
    "]\n",
    "evaluation_df = run_evaluation(collection=collection, test_user_queries=test_user_queries, top_k=3)\n",
    "print(evaluation_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
